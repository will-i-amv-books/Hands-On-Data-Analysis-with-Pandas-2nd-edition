{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 1\n",
    "\n",
    "With the earthquakes.csv file, select all the earthquakes in Japan with a\n",
    "magnitude of 4.9 or greater using the mb magnitude type."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 2\n",
    "\n",
    "Create bins for each full number of earthquake magnitude (for instance, the first bin\n",
    "is (0, 1], the second is (1, 2], and so on) with the ml magnitude type and count how\n",
    "many are in each bin.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 3\n",
    "\n",
    "Using the faang.csv file, group by the ticker and resample to monthly frequency.\n",
    "Make the following aggregations:\n",
    "- Mean of the opening price\n",
    "- Maximum of the high price\n",
    "- Minimum of the low price\n",
    "- Mean of the closing price\n",
    "- Sum of the volume traded"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 4\n",
    "\n",
    "Build a crosstab with the earthquake data between the tsunami column and the\n",
    "magType column. Rather than showing the frequency count, show the maximum\n",
    "magnitude that was observed for each combination. Put the magnitude type along\n",
    "the columns."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 5\n",
    "\n",
    "Calculate the rolling 60-day aggregations of the OHLC data by ticker for the\n",
    "FAANG data. Use the same aggregations as exercise 3."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 6\n",
    "\n",
    "Create a pivot table of the FAANG data that compares the stocks. Put the ticker in\n",
    "the rows and show the averages of the OHLC and volume traded data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 7\n",
    "\n",
    "Calculate the Z-scores for each numeric column of Amazon's data ( ticker is\n",
    "AMZN) in Q4 2018 using apply()."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 8\n",
    "\n",
    "Add event descriptions:\n",
    "\n",
    "* Create a dataframe with the following three columns: ticker , date , and event. The columns should have the following values:\n",
    "\n",
    "    - ticker : 'FB'\n",
    "    - date : ['2018-07-25', '2018-03-19', '2018-03-20']\n",
    "    - event : ['Disappointing user growth announced after close.', 'Cambridge Analytica story', 'FTC investigation']\n",
    "\n",
    "* Set the index to ['date', 'ticker'] .\n",
    "\n",
    "* Merge this data with the FAANG data using an outer join."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 9\n",
    "\n",
    "Use the transform() method on the FAANG data to represent all the\n",
    "values in terms of the first date in the data. To do so, divide all the values for\n",
    "each ticker by the values for the first date in the data for that ticker. This is\n",
    "referred to as an index, and the data for the first date is the base ( https://\n",
    "ec.europa.eu/eurostat/statistics-explained/index.php/\n",
    "Beginners:Statistical_concept_-_Index_and_base_year ). When\n",
    "data is in this format, we can easily see growth over time. Hint: transform() can\n",
    "take a function name."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 10\n",
    "\n",
    "The European Centre for Disease Prevention and Control (ECDC) provides\n",
    "an open dataset on COVID-19 cases called daily number of new reported cases\n",
    "of COVID-19 by country worldwide ( https://www.ecdc.europa.eu/\n",
    "en/publications-data/download-todays-data-geographic-\n",
    "distribution-covid-19-cases-worldwide ). This dataset is updated daily,\n",
    "but we will use a snapshot that contains data through September 18, 2020. Complete\n",
    "the following tasks to practice the skills you've learned up to this point in the book:\n",
    "\n",
    "* Prepare the data:\n",
    "    - Read in the data in the covid19_cases.csv file.\n",
    "    - Create a date column by parsing the dateRep column into a datetime.\n",
    "    - Set the date column as the index.\n",
    "    - Use the replace() method to update all occurrences of United_States_of_America and United_Kingdom to USA and UK, respectively.\n",
    "    - Sort the index."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "globalCases = pd\\\n",
    "    .read_csv('exercises/covid19_cases.csv')\\\n",
    "    .assign(\n",
    "        date=lambda x: pd.to_datetime(\n",
    "            x.dateRep,\n",
    "            format='%d/%m/%Y'\n",
    "        )\n",
    "    )\\\n",
    "    .set_index('date')\\\n",
    "    .replace('United_States_of_America', 'USA')\\\n",
    "    .replace('United_Kingdom', 'UK')\\\n",
    "    .sort_index()\n",
    "\n",
    "globalCases.head()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "a) For the five countries with the most cases (cumulative), find the day with the largest number of cases."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "b) Find the 7-day average change in COVID-19 cases for the last week in the data for the five countries with the most cases."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "c) Find the first date that each country other than China had cases."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "d) Rank the countries by cumulative cases using percentiles."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<hr>\n",
    "<div style=\"overflow: hidden; margin-bottom: 10px;\">\n",
    "    <div style=\"float: left;\">\n",
    "        <a href=\"./python_101.ipynb\">\n",
    "            <button>Python 101</button>\n",
    "        </a>\n",
    "    </div>\n",
    "    <div style=\"float: right;\">\n",
    "        <a href=\"../../solutions/ch_01/solutions.ipynb\">\n",
    "            <button>Solutions</button>\n",
    "        </a>\n",
    "        <a href=\"../ch_02/1-pandas_data_structures.ipynb\">\n",
    "            <button>Chapter 2 &#8594;</button>\n",
    "        </a>\n",
    "    </div>\n",
    "</div>\n",
    "<hr>"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('env': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "5e4f50eee1bd8c051d8159abc56ebbdb16ed7d834d93823d0850b2afd16c59c4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}